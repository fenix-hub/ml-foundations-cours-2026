{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66ac700",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "In questa lezione introduciamo la linear regression, uno dei modelli più fondamentali nel supervised\n",
    "learning. Nonostante la sua apparente semplicità, la linear regression fornisce un framework unificante per\n",
    "molte idee chiave nel Machine Learning, inclusa la loss minimisation, l'optimisation, la probabilistic\n",
    "modelling, e la feature representation.  \n",
    "\n",
    "Come tutti i modelli di unsupervised learning, Linear Regression si basa sul concetto che, dato un Training set costituito da $ n $ coppie input-output, al momento della predizione vogliamo calcolare una predizione  \n",
    "$ \\hat{y}^* = \\hat{f}(x^*) $  \n",
    "che approssimi l'output vero sconosciuto $ y^* $, ma un buon fit sul training set da solo non è sufficiente.  \n",
    "\n",
    "Un'assunzione di modello comune è che l'output osservato sia generato secondo una funzione deterministica sconosciuta che vogliamo modellare $ f(x) $ e un termine di rumore casuale $ epsilon $ che è indipendente da $ x $.  \n",
    "\n",
    "Per rendere il problema trattabile, restringiamo la classe di predittori ammissibili e assumiamo un modello che è *lineare nei parametri*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9276d7",
   "metadata": {},
   "source": [
    "### Predittore Affine\n",
    "\n",
    "Definiamo il modello di linear regression come  \n",
    "$ \\hat{y}(x,\\theta) = \\theta^T x $  \n",
    "dove $ x = [1, x_1 ... x_p] $ e $ \\theta = [\\theta_0 ... \\theta_p] $  \n",
    "La prima componente di $ x $ è 1 in modo che il modello possa imparare un termine di intercept $ \\theta_0 $. Questo rende il predittore *affine* piuttosto che puramente lineare nei feature originali.  \n",
    "\n",
    "### Modello di Misurazione\n",
    "Adesso modelliamo il processo di generazione dei dati come una funzione che vede l'output osservato $ y $ come la somma di una componente lineare sistematica (vettore di parametri $ \\theta^T $ moltiplicato per il vettore di input $ x $ ) più un termine di rumore casuale.\n",
    "\n",
    "### Predizione\n",
    "Per un nuovo input $ x^* $ dato, una predizione sarà $ \\hat{y}^* = \\hat{\\theta}^T x^* $ .   \n",
    "Possiamo adesso definire il *residual* $ r_i $ come la distanza tra il valore di output reale $ y_i $ per un campione dato e il suo valore preditto $ \\hat{y}_i $  \n",
    "\n",
    "Ricorda che per il *training* usiamo notazione a matrice sia per input che output, quindi:  \n",
    "Modello di misurazione: $ Y = X\\theta + \\epsilon $  \n",
    "Predittore affine: $ \\hat{Y} = X\\theta  $  \n",
    "dove la prima colonna di $ X $ è tutta 1 per essere affine (l'intercept viene imparato insieme agli altri parametri).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d7b31",
   "metadata": {},
   "source": [
    "# Loss function $ L(\\hat{y},y) $ e Cost function $J(\\theta)$\n",
    "\n",
    "Per addestrare un modello di linear regression abbiamo bisogno di definire cosa è una predizione *buona* o *cattiva*.  \n",
    "Usiamo una **loss function** $ L(\\hat{y},y) $ per misurare la discrepanza tra l'output *effettivo* $ y $ e l'output *predetto* $ \\hat(y) $ per *un singolo esempio di addestramento*.  \n",
    "Per problemi di regression una pratica comune è usare *squared error loss* come loss function:  \n",
    "$ L(\\hat{y},y) = (\\hat{y},y)^2 = (\\theta^{T}x - y)^2$  \n",
    "Questa funzione è utile perché se il valore predetto è uguale al valore reale la loss è 0, e più la predizione è lontana dal valore osservato, più l'errore ha impatto sull'apprendimento.  \n",
    "\n",
    "Tuttavia, quando addestriamo il nostro predictor, non addestriamo solo su un singolo campione, ma su l'intero dataset. Se la *loss function* è definita su un singolo campione, possiamo definire una **cost function** su l'intero dataset come l'aggregazione di tutta la *loss* su tutti i dati di addestramento.  \n",
    "Quindi per un dataset fatto di $ n $ campioni, la cost function sarà:  \n",
    "$ J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} L(\\hat{y}(x_i,\\theta),y_i) $  \n",
    "e se $ L $ è la *squared error loss*:  \n",
    "$   J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} L(\\theta^{T}x_i - y_i)^2 = \\frac{1}{n} || X\\theta - y ||^2 $  \n",
    "\n",
    "### Least squares  \n",
    "Nota che la nostra cost function per una squared error loss dipende dalla *somma dei residui al quadrato*, poiché stiamo usando notazione a matrice, dove tutte le righe corrispondono al residuo del campione $i$-esimo: $ r_i = \\theta^{T}x_i - y_i $  \n",
    "Per costruire un predictor che predica valori il più possibile vicino agli output osservati, abbiamo bisogno di fondamentalmente minimizzare il vettore di parametri $ \\theta $ , il che significa minimizzare la somma dei residui al quadrato: è per questo che per addestrare un regressore lineare in queste circostanze lavoriamo con il problema dei *least squares* (quadrati MINIMI). Il vettore di parametri minimo è: $ \\hat{\\theta} = \\text{arg}\\min_{\\theta}||X\\theta - Y||^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23db68",
   "metadata": {},
   "source": [
    "### Soluzione\n",
    "Per trovare un modo di calcolare un possibile $\\hat{\\theta}$ possiamo derivare la soluzione *closed-form* del problema dei least squares usando il calcolo.  \n",
    "Prima espandiamo $ J(\\theta) $ espandendo la norma al quadrato, poi calcoliamo il gradiente di $ J(\\theta) $ rispetto a $ \\theta $.  Otteniamo:  \n",
    "$ \\nabla_{\\theta}J(\\theta) = -2X^{T}Y + 2X^{T}X\\theta $  \n",
    "Possiamo osservare che esponendo il $ 2X^{T} $ termine otteniamo $  \\nabla_{\\theta}J(\\theta) = 2X^{T}(X\\theta - Y) $, e quindi interpretiamo il gradiente come un vettore che punta nella direzione dove la pendenza è ripida, a seconda del *residuale*.  \n",
    "Impostando il gradiente a zero, otteniamo le *normal equations*:  \n",
    "$X^{T}X\\hat{\\theta}=X^{T}Y$  \n",
    "\n",
    "Possiamo ottenere la soluzione $ \\hat{\\theta} $ soltanto se il termine $ X^{T}X $ è invertibile, il che ha bisogno che le colonne di $ X $ siano indipendenti (per ammettere una soluzione unica). Inoltre, sappiamo che tale soluzione sarà ottimale poiché la matrice Hessiana di J $\\nabla^{2}_{\\theta}J = 2X^{T}X $ contiene il termine $ X^{T}X $ che è positivo semidefinito, e quindi la cost function di J è convessa. Grazie a questa proprietà, qualsiasi punto *stazionario* è un minimizzatore globale, poiché un punto stazionario è un $x_0$ per il quale $ f(x_0)' = 0 $. \n",
    "\n",
    "Le colonne di $ X $ sono indipendenti se: nessuna feature è la combinazione lineare esatta delle altre, e il numero di campioni $ n $ è più grande del numero di parametri $ p + 1 $.  \n",
    "Se il termine $ X^{T}X $ non è invertibile, abbiamo bisogno di calcolare lo *pseudo-inverse* di tale termine usando metodi di algebra lineare numerica come *QR Decomposition* o *Singular Value Decomposition (SVD)*.  \n",
    "\n",
    "È importante notare che lo *squared linear regression* è così popolare per tutte le osservazioni precedenti: soltanto questo metodo fornisce una **soluzione closed-form** il che significa che una soluzione esatta è data usando un numero finito di operazioni standard. Molte altre loss functions non ammettono tale soluzione esplicita, e richiedono invece metodi di *ottimizzazione iterativa*.  \n",
    "\n",
    "Comunque, la **squared error loss** function è utile quando abbiamo a che fare con problemi di linear regression su dataset piccoli. Se un dataset è molto grande, o la funzione obiettivo non ammette un minimizzatore analitico, può essere computazionalmente costoso - quindi usiamo altri metodi, che non sono in forma chiusa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63455631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Applichiamo un regressore lineare al dataset sulla qualità dei vini rossi.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
