{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0964eeed",
   "metadata": {},
   "source": [
    "# Alberi Decisionali\n",
    "\n",
    "nella lezione precedente abbiamo studiato che k-NN è un modello che predice nuovi valori modellando un predittore piecewise-constant. Ogni pezzo del predittore è una funzione che implicitamente mappa un insieme di valori a una regione decisionale.  \n",
    "Un'alternativa a k-NN sono gli **alberi decisionali** che sono complementari a k-NN nel fatto che definiscono anche regioni, ma il modo in cui sono definite è diverso. Specificamente, gli alberi decisionali **esplicitamente** definiscono regioni decisionali basate su regole applicate alle variabili di input.\n",
    "\n",
    "L'idea di base dietro un albero decisionale è usare un modello basato su regole organizzato come un albero binario.  \n",
    "Questo albero binario partiziona lo spazio di input $ R^p $ in sottorigioni $ R_m $ che sono disgiunte $ R_m \\cup R_{m'} = 0 \\text{ per } m \\ne m' $, e dove $ M $ è il numero di regioni  \n",
    "\n",
    "$ \\mathbb{R}^p = \\bigcup_{m=1}^{M} R_m $  \n",
    "\n",
    "insieme a un predittore piecewise-constant  \n",
    "\n",
    "$ \\hat{y}(x) = c_m \\text{ se } x \\in{R_m} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b454ad",
   "metadata": {},
   "source": [
    "## Regole e struttura dell'albero\n",
    "\n",
    "Le regioni disgiunte sono create applicando ricorsivamente un insieme di regole sulle feature di input.  \n",
    "Iniziamo dalla radice, dove viene applicata una regola: $ x_j \\leq t $ ? Dove $ t $ è una soglia e $ x_j $ è una feature di input.  \n",
    "Se la condizione è soddisfatta, viene prodotta una regione Foglia (sinistra), che definisce una regione decisionale $ R_m $ dove la funzione assume un valore costante $ c_m $, per esempio $ R_1 -> c_1 $.  \n",
    "Se la condizione non è soddisfatta, l'input viene inviato al figlio destro che può essere un *nodo interno* (con un nuovo valore di soglia $ s $ per una nuova feature di input $ x_k $) o un *nodo foglia* a seconda del caso.  \n",
    "\n",
    "Per ogni regione foglia definita $ R_m $ possiamo identificare l'insieme di indici dei campioni di addestramento appartenenti a quella regione:  \n",
    "$ S_m = \\{ i : x_i \\in R_m \\} $ \n",
    "Quindi per ogni regione foglia il predittore produce un valore costante $ c_m $ e questo valore dipende solo dai campioni dell'insieme di addestramento associati all'insieme di indici $ S_m $  \n",
    "\n",
    "Come abbiamo visto in K-NN, il valore effettivo della costante $ c_m $ prodotta dal predittore dipende da un calcolo che varia da un problema di classificazione o regressione.  \n",
    "\n",
    "Per la *regressione*, viene utilizzato il valore medio degli output di addestramento $ y_i $ nella regione $ R_m $.  \n",
    "$ c_m = \\frac{1}{|S_m|}\\sum_{i\\in S_m} y_i $  \n",
    "Per la *classificazione*, la predizione è la classe più frequente tra i campioni in $ S_m $, dove $ n_{c}(S_m) $ denota il numero di campioni in $ S_m $ appartenenti alla classe $ c $.  \n",
    "$ c_m = \\arg\\max_{c \\in \\mathcal{C}} n_c(S_m). $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37b266",
   "metadata": {},
   "source": [
    "Le regole vengono applicate per consentire all'albero decisionale di dividere lo spazio di input in due regioni più piccole progressivamente. La regola agisce come un *taglio geometrico* che dividere una regione in una regione sinistra $ R_{L}(j,\\leq t) $ e una regione destra $ R_{R}(j,t) $. Da una prospettiva geometrica, questa operazione corrisponde a dividere lo spazio di input con un iperpiano che è ortogonale a uno degli assi coordinati. Da una prospettiva statistica, separa i campioni di addestramento in due gruppi, che vengono valutati indipendentemente.  \n",
    "\n",
    "Lo scopo della divisione è *ridurre l'incertezza* sulla variabile di output. **Una buona divisione è quella che produce nodi figli in cui gli output sono più concentrati, meno variabili, o più coerenti rispetto al nodo genitore**.  \n",
    "\n",
    "Quindi può sorgere una domanda: *quale è la migliore divisione che possiamo scegliere?*  \n",
    "La risposta dipende dal compito di apprendimento. Sia nella regressione che nella classificazione, il principio guida è lo stesso: una buona divisione è quella che produce nodi figli che sono più omogenei, o meno incerti, dal nodo genitore.  Per rispondere a questa domanda, ora introduciamo il concetto di $ \\text{impurità}$ e selezioniamo la divisione che produce la **riduzione più grande dell'impurità**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740b602",
   "metadata": {},
   "source": [
    "# Regressione\n",
    "\n",
    "Nei problemi di regressione, le variabili di output sono numeriche. Quindi il concetto di omogeneità all'interno di un nodo corrisponde ad avere valori di output che sono vicini l'uno all'altro.  \n",
    "Una quantità in grado di descrivere la proprietà di \"vicinanza\" dei valori di output è l'Errore Quadratico Medio (MSE) che misura *quanto sono dispersi gli output attorno alla loro media*.  \n",
    "Per un dato nodo della regione $ R_m $ associato a un insieme di indici $ S $, il valore medio (media) di output è:  \n",
    "$\\bar{y}_S = \\frac{1}{\\lvert S\\rvert} \\sum_{i \\in S} y_i$  \n",
    "Quindi possiamo misurare quanto ogni valore di output $ y_i $ è distante dalla media $ \\bar{y}_S $, sommiamo tutte le distanze di ogni output e calcoliamo il valore medio  \n",
    "$\\mathrm{MSE}(S)=\\frac{1}{\\lvert S\\rvert}\\sum_{i\\in S}\\left(y_i-\\bar{y}_S\\right)^2$  \n",
    "Minore è il valore MSE, più vicini e meno dispersi sono i valori di output all'interno di un nodo.  \n",
    "   \n",
    "## Riduzione dell'impurità\n",
    "Possiamo ora valutare la qualità di una divisione misurando la riduzione dell'impurità causata da tale divisione. Una volta che una divisione è stata fatta abbiamo due partizioni di S, e possiamo calcolare la media ponderata delle impurità (quindi la media ponderata dell'MSE delle due regioni), dove il peso è il valore di $ \\frac{| S_{L/R} |}{| S |} $, e sommiamo i due MSE ponderati per ottenere l'$ MSE_{post} $.  \n",
    "La qualità della divisione è:  $ \\Delta_{reg}(j,t) = MSE(S) - MSE_{post} $  \n",
    "\n",
    "La **divisione ottimale** è quella che massimizza $ \\Delta_{reg}(j,t) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b37d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average output value: 3.0666666666666664\n",
      "MSE of the whole dataset: 1.6788888888888887\n",
      "MSE after the split: 0.4516666666666666\n",
      "Impurity Delta: 1.227222222222222\n"
     ]
    }
   ],
   "source": [
    "# Esempio\n",
    "# consideriamo il seguente dataset di una feature x_1 e una variabile target y:\n",
    "\n",
    "dataset = [\n",
    "    (1.0, 1.2),\n",
    "    (1.8, 1.8),\n",
    "    (2.7, 2.6),\n",
    "    (3.2, 3.9),\n",
    "    (3.8, 4.1),\n",
    "    (4.5, 4.8)\n",
    "]\n",
    "\n",
    "# trattiamo output numerici, quindi questo è un problema di regressione. l'obiettivo è valutare la qualità di una divisione, per esempio, x_1 <= 2.5\n",
    "# abbiamo bisogno di calcolare l'MSE_post, che ha bisogno dell'MSE di ogni divisione. Per l'MSE abbiamo bisogno innanzitutto del valore medio/medio output:\n",
    "\n",
    "Y_avg = sum(y for _, y in dataset) / len(dataset)\n",
    "print(\"Valore di output medio:\", Y_avg)\n",
    "\n",
    "MSE_Y = sum((y - Y_avg) ** 2 for _, y in dataset) / len(dataset)\n",
    "print(\"MSE dell'intero dataset:\", MSE_Y)\n",
    "\n",
    "# adesso applichiamo la divisione e calcoliamo l'MSE_post, dalla media ponderata dell'MSE di ogni divisione:\n",
    "rule = 2.5\n",
    "split_left = [(x, y) for x, y in dataset if x <= rule]\n",
    "split_right = [(x, y) for x, y in dataset if x > rule]\n",
    "Y_avg_left = sum(y for _, y in split_left) / len(split_left)\n",
    "Y_avg_right = sum(y for _, y in split_right) / len(split_right)\n",
    "MSE_left = sum((y - Y_avg_left) ** 2 for _, y in split_left) / len(split_left)\n",
    "MSE_right = sum((y - Y_avg_right) ** 2 for _, y in split_right) / len(split_right)\n",
    "MSE_post = (len(split_left) * MSE_left + len(split_right) * MSE_right) / len(dataset)\n",
    "print(\"MSE dopo la divisione:\", MSE_post)\n",
    "\n",
    "# adesso possiamo calcolare il Delta di impurità:\n",
    "Delta = MSE_Y - MSE_post\n",
    "print(\"Delta di impurità:\", Delta)\n",
    "\n",
    "## Stamperà \"Impurity Delta: 1.227222222222222\"\n",
    "# poiché Delta è positivo, significa che la divisione ha ridotto l'MSE, e quindi è una buona divisione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b1937",
   "metadata": {},
   "source": [
    "# Classificazione\n",
    "\n",
    "Nei problemi di classificazione, le variabili di output sono categoriche. Quindi il concetto di omogeneità all'interno di un nodo corrisponde ad avere valori di output che sono prevalentemente di una singola classe.  \n",
    "Una quantità in grado di descrivere la proprietà di \"predominanza\" dei valori di output è la proporzione $ p_{c}(S) $ di un campione appartenente alla classe $ c $ in un nodo $ S $, che misura *la classe più frequente/predominante in una regione*.  \n",
    "Per un dato nodo della regione $ R_m $ associato a un insieme di indici $ S $, il valore di proporzione di una classe $ c $ è:  \n",
    "$\\bar{y}_S = \\frac{1}{\\lvert S\\rvert} \\sum_{i \\in S} y_i$  \n",
    "La misura di impurità quantifica quanto mischiate sono le classi all'interno di un nodo. Possiamo usare due misure per l'impurità: Gini e Entropia.  \n",
    "\n",
    "## Gini\n",
    "L'impurità di Gini è zero se tutti i campioni all'interno di una regione appartengono alla stessa classe, e aumenta man mano che la distribuzione di classe diventa più uniforme.  \n",
    "$G(S)=1-\\sum_{c\\in\\mathcal{C}}p_c(S)^2$  \n",
    "\n",
    "## Entropia\n",
    "L'entropia misura l'incertezza associata alla predizione dell'etichetta di classe, e ha un'interpretazione teorica dell'informazione.  \n",
    "$H(S) = -\\sum_{c \\in C} p_c(S)\\log_2 p_c(S)$  \n",
    "\n",
    "## Riduzione dell'impurità   \n",
    "Possiamo ora valutare la qualità di una divisione misurando la riduzione dell'impurità causata da tale divisione. Una volta che una divisione è stata fatta abbiamo due partizioni di S, e possiamo calcolare l'impurità post-divisione come la somma della media ponderata della misura di impurità - sia Gini che Entropia - di ogni partizione, ottenendo l'$ I_{post} $.  \n",
    "Il miglioramento associato alla divisione è:  $ \\Delta_{cls}(j,t) = I(S) - I_{post} $  \n",
    "\n",
    "La **divisione ottimale** è quella che massimizza $ \\Delta_{cls}(j,t) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of class A: 0.5\n",
      "Proportion of class B: 0.5\n",
      "Gini of the whole dataset: 0.5\n",
      "Entropy of the whole dataset: 1.0\n",
      "Proportion of class A in left split: 0.75\n",
      "Proportion of class B in left split: 0.25\n",
      "Proportion of class A in right split: 0.3333333333333333\n",
      "Proportion of class B in right split: 0.6666666666666666\n",
      "Gini of left split: 0.375\n",
      "Gini of right split: 0.4444444444444444\n",
      "Entropy of left split: 0.8112781244591328\n",
      "Entropy of right split: 0.9182958340544896\n",
      "Gini after the split: 0.41666666666666663\n",
      "Entropy after the split: 0.8754887502163469\n",
      "Impurity Delta for Gini: 0.08333333333333337\n",
      "Impurity Delta for Entropy: 0.12451124978365313\n"
     ]
    }
   ],
   "source": [
    "# Esempio\n",
    "## Usiamo un dataset con 10 campioni, classe A = 5 e classe B = 5, e una divisione candidata che produce: SL: A=3, B=1 e SR: A=2, B=4.\n",
    "import numpy as np\n",
    "\n",
    "dataset = [ 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B' ]\n",
    "# per prima cosa calcoliamo la proporzione di ogni classe nell'intero dataset:\n",
    "p_A = dataset.count('A') / len(dataset)\n",
    "p_B = dataset.count('B') / len(dataset)\n",
    "print(\"Proportion of class A:\", p_A)\n",
    "print(\"Proportion of class B:\", p_B)\n",
    "proportions = [p_A, p_B]\n",
    "\n",
    "# Ora calcoliamo Gini ed Entropia per l'intero dataset:\n",
    "Gini_Y = 1 - sum(p ** 2 for p in proportions)\n",
    "Entropy_Y = -sum(p * np.log2(p) for p in proportions if p > 0)\n",
    "print(\"Gini of the whole dataset:\", Gini_Y)\n",
    "print(\"Entropy of the whole dataset:\", Entropy_Y)\n",
    "\n",
    "# Ora applichiamo la divisione e calcoliamo Gini ed Entropia per ciascuna partizione:\n",
    "split_left = ['A', 'A', 'A', 'B']\n",
    "split_right = ['A', 'A', 'B', 'B', 'B', 'B']\n",
    "p_A_left = split_left.count('A') / len(split_left)\n",
    "p_B_left = split_left.count('B') / len(split_left)\n",
    "p_A_right = split_right.count('A') / len(split_right)\n",
    "p_B_right = split_right.count('B') / len(split_right)\n",
    "print(\"Proportion of class A in left split:\", p_A_left)\n",
    "print(\"Proportion of class B in left split:\", p_B_left)\n",
    "print(\"Proportion of class A in right split:\", p_A_right)\n",
    "print(\"Proportion of class B in right split:\", p_B_right)\n",
    "proportions_left = [p_A_left, p_B_left]\n",
    "proportions_right = [p_A_right, p_B_right]\n",
    "\n",
    "Gini_left = 1 - sum(p ** 2 for p in proportions_left)\n",
    "Gini_right = 1 - sum(p ** 2 for p in proportions_right)\n",
    "Entropy_left = -sum(p * np.log2(p) for p in proportions_left if p > 0)\n",
    "Entropy_right = -sum(p * np.log2(p) for p in proportions_right if p > 0)\n",
    "print(\"Gini of left split:\", Gini_left)\n",
    "print(\"Gini of right split:\", Gini_right)\n",
    "print(\"Entropy of left split:\", Entropy_left)\n",
    "print(\"Entropy of right split:\", Entropy_right)\n",
    "\n",
    "# Ora calcoliamo la media ponderata di Gini ed Entropia per le partizioni:\n",
    "Gini_post = (len(split_left) * Gini_left + len(split_right) * Gini_right) / len(dataset)\n",
    "Entropy_post = (len(split_left) * Entropy_left + len(split_right) * Entropy_right) / len(dataset)\n",
    "print(\"Gini after the split:\", Gini_post)\n",
    "print(\"Entropy after the split:\", Entropy_post)\n",
    "\n",
    "# Infine calcoliamo il Delta di impurita per Gini ed Entropia:\n",
    "Delta_Gini = Gini_Y - Gini_post\n",
    "Delta_Entropy = Entropy_Y - Entropy_post\n",
    "print(\"Impurity Delta for Gini:\", Delta_Gini)\n",
    "print(\"Impurity Delta for Entropy:\", Delta_Entropy)\n",
    "\n",
    "# Possiamo osservare che la riduzione di impurita con Gini e << 0.1, quindi la divisione non introduce purezza ed e meglio lasciare il dataset non diviso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17961e6",
   "metadata": {},
   "source": [
    "# Crescita di un albero decisionale\n",
    "Un albero decisionale viene costruito applicando ricorsivamente la procedura di divisione descritta sopra.  \n",
    "Algoritmo (Crescita dell'albero decisionale).  \n",
    "1. Inizia con tutti i campioni di addestramento nel nodo radice.  \n",
    "2. Se una condizione di arresto e soddisfatta, crea una foglia e assegna una predizione.  \n",
    "3. Altrimenti, valuta tutte le divisioni candidate e seleziona quella che massimizza la riduzione dell'impurita.  \n",
    "4. Partiziona i dati secondo la divisione selezionata e ripeti la procedura su ciascun nodo figlio.  \n",
    "\n",
    "Questo processo ricorsivo continua finche tutte le foglie soddisfano un criterio di arresto.\n",
    "\n",
    "## Criteri di arresto e pruning\n",
    "Senza un criterio di arresto, la complessita dell'albero decisionale cresce, producendo una accuratezza perfetta sui dati di addestramento (ogni singolo campione di addestramento corrisponde a una foglia) ma scarsa generalizzazione.  \n",
    "Possiamo applicare diversi criteri di arresto, principalmente di due tipi: pre-pruning e post-pruning. L'obiettivo e *ridurre la varianza e migliorare la generalizzazione*.\n",
    "\n",
    "### Pre-pruning\n",
    "Il pre-pruning consiste nell'applicare regole durante la generazione dell'albero decisionale per fermare le divisioni. Si possono applicare diverse regole e fermiamo la divisione in un nodo associato all'insieme di indici $ S $ se almeno una delle seguenti condizioni vale.  \n",
    "1. **Nodo puro**, un nodo e puro quando l'incertezza sull'output predetto e zero. Per la *regressione* corrisponde a una varianza (MSE) pari a 0 per un dato nodo; per la *classificazione* corrisponde a un indice di impurita uguale a 0, equivalente a una proporzione pari a 1 per una data classe $ c $.  \n",
    "2. **Troppi pochi campioni**, possiamo definire una soglia di campioni minimi necessari per dividere, o una *dimensione minima della foglia* richiesta per dividere.  \n",
    "3. **Profondita massima raggiunta**, possiamo fermare la divisione quando raggiungiamo un valore specifico $ d_{max} $ di profondita per un nodo nell'albero $ depth(S) $.  \n",
    "4. **Nessun miglioramento significativo**, per ogni divisione candidata $ (j,t) $ possiamo calcolare la riduzione di impurita $ \\Delta(j,t) $ e verificare se viene raggiunto un miglioramento minimo $ \\epsilon $.  \n",
    "5. **Nessuna divisione valida**, fermare se tutte le feature sono costanti sui campioni in S, o se ogni divisione candidata crea un figlio vuoto.  \n",
    "Questi criteri controllano la complessita del modello durante l'addestramento e riducono il rischio di overfitting\n",
    "impedendo all'albero di adattarsi a pattern spurii e di piccola scala nel training set.\n",
    "\n",
    "### Post-pruning\n",
    "In questo caso lasciamo crescere l'albero fino alla fine e poi semplifichiamo rimuovendo rami (decisioni) che non migliorano le prestazioni sui dati di validazione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3906d484",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59205749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 17000 entries, 0 to 16999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           17000 non-null  float64\n",
      " 1   latitude            17000 non-null  float64\n",
      " 2   housing_median_age  17000 non-null  float64\n",
      " 3   total_rooms         17000 non-null  float64\n",
      " 4   total_bedrooms      17000 non-null  float64\n",
      " 5   population          17000 non-null  float64\n",
      " 6   households          17000 non-null  float64\n",
      " 7   median_income       17000 non-null  float64\n",
      " 8   median_house_value  17000 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Studiamo ora lo stesso caso usato in kNN ma con un albero decisionale.\n",
    "\n",
    "import pandas as pd\n",
    "train_set = pd.read_csv(\"/workspaces/ml-foundations-cours-2026/california_housing/california_housing_train.csv\")\n",
    "test_set = pd.read_csv(\"/workspaces/ml-foundations-cours-2026/california_housing/california_housing_test.csv\")\n",
    "\n",
    "print(train_set.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af228173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizziamo i dati di train. Poiche lavoriamo con feature continue, usiamo la standardizzazione (Z-score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Lo StandardScaler di sklearn e esattamente cio che vogliamo: { z = (x - u) / s } dove u e la media dei campioni di training o zero se with_mean=False, e s e la deviazione standard dei campioni di training o uno se with_std=False.\n",
    "train_set_scaled = scaler.fit_transform(train_set.drop(\"median_house_value\", axis=1))\n",
    "train_set_scaled = pd.DataFrame(train_set_scaled, columns=train_set.columns[:-1])\n",
    "train_set_scaled[\"median_house_value\"] = train_set[\"median_house_value\"]\n",
    "\n",
    "X = train_set_scaled.drop(\"median_house_value\", axis=1)\n",
    "y = train_set_scaled[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dffec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=criterion,-%7B%22squared_error%22%2C%20%22friedman_mse%22%2C%20%22absolute_error%22%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%22poisson%22%7D%2C%20default%3D%22squared_error%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"squared_error\", \"friedman_mse\", \"absolute_error\",             \"poisson\"}, default=\"squared_error\"<br><br>The function to measure the quality of a split. Supported criteria<br>are \"squared_error\" for the mean squared error, which is equal to<br>variance reduction as feature selection criterion and minimizes the L2<br>loss using the mean of each terminal node, \"friedman_mse\", which uses<br>mean squared error with Friedman's improvement score for potential<br>splits, \"absolute_error\" for the mean absolute error, which minimizes<br>the L1 loss using the median of each terminal node, and \"poisson\" which<br>uses reduction in the half mean Poisson deviance to find splits.<br><br>.. versionadded:: 0.18<br>   Mean Absolute Error (MAE) criterion.<br><br>.. versionadded:: 0.24<br>    Poisson deviance criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.<br><br>For an example of how ``max_depth`` influences the model, see<br>:ref:`sphx_glr_auto_examples_tree_plot_tree_regression.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multioutput regressions (i.e. when `n_outputs_ > 1`),<br>  - regressions trained on data with missing values.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usiamo un Decision Tree Regressor di sklearn:\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_regressor = DecisionTreeRegressor(criterion = 'squared_error', random_state=42)\n",
    "tree_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo le prestazioni del modello sul test set:\n",
    "test_set_scaled = scaler.transform(test_set.drop(\"median_house_value\", axis=1))\n",
    "test_set_scaled = pd.DataFrame(test_set_scaled, columns=test_set.columns[:-1])\n",
    "test_set_scaled[\"median_house_value\"] = test_set[\"median_house_value\"]\n",
    "\n",
    "X_test = test_set_scaled.drop(\"median_house_value\", axis=1)\n",
    "y_test = test_set_scaled[\"median_house_value\"]\n",
    "\n",
    "y_pred = tree_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on the test set: 4630499719.639334\n"
     ]
    }
   ],
   "source": [
    "# Valutiamo le prestazioni del modello\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error on the test set:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019daf3c",
   "metadata": {},
   "source": [
    "Albero decisionale --> Classificazione! Non ha molto senso usare un DT su un problema di regressione. Applichiamolo a un problema di classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a25dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  Gli input includono test oggettivi (ad es. valori di pH) e l'output e basato su dati sensoriali\n",
    "  (mediana di almeno 3 valutazioni fatte da esperti di vino). Ogni esperto ha valutato la qualita\n",
    "  del vino tra 0 (molto cattivo) e 10 (eccellente). Diversi metodi di data mining sono stati applicati\n",
    "  a questi dataset con un approccio di regressione. Il modello a support vector machine ha ottenuto\n",
    "  i risultati migliori. Sono state calcolate diverse metriche: MAD, matrice di confusione per una\n",
    "  tolleranza di errore fissa (T), ecc. Inoltre, tracciamo le importanze relative delle variabili di input\n",
    "  (misurate tramite una procedura di analisi di sensibilita).\n",
    "'''\n",
    "\n",
    "whine_set = pd.read_csv(\"/workspaces/ml-foundations-cours-2026/whine-quality/winequality-red.csv\", sep=';')\n",
    "print(whine_set.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d94e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "5    551\n",
      "6    506\n",
      "7    157\n",
      "4     43\n",
      "8     13\n",
      "3      9\n",
      "Name: count, dtype: int64\n",
      "Pred:  6.0 True:  6\n",
      "Mean Squared Error on the test set: 0.6125\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  Gli input includono test oggettivi (ad es. valori di pH) e l'output e basato su dati sensoriali\n",
    "  (mediana di almeno 3 valutazioni fatte da esperti di vino). Ogni esperto ha valutato la qualita\n",
    "  del vino tra 0 (molto cattivo) e 10 (eccellente). Diversi metodi di data mining sono stati applicati\n",
    "  a questi dataset con un approccio di regressione. Il modello a support vector machine ha ottenuto\n",
    "  i risultati migliori. Sono state calcolate diverse metriche: MAD, matrice di confusione per una\n",
    "  tolleranza di errore fissa (T), ecc. Inoltre, tracciamo le importanze relative delle variabili di input\n",
    "  (misurate tramite una procedura di analisi di sensibilita).\n",
    "'''\n",
    "\n",
    "# dividiamo il dataset in train e test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(whine_set, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalizziamo\n",
    "scaler = StandardScaler()\n",
    "train_set_scaled = scaler.fit_transform(train_set.drop(\"quality\", axis=1))\n",
    "train_set_scaled = pd.DataFrame(train_set_scaled, columns=train_set.columns[:-1])\n",
    "train_set_scaled[\"quality\"] = train_set[\"quality\"].reset_index(drop=True)\n",
    "\n",
    "# istanziamo un decision tree regressor e lo alleniamo sui dati di training:\n",
    "X = train_set_scaled.drop(\"quality\", axis=1)\n",
    "y = train_set_scaled[\"quality\"]\n",
    "print(y.value_counts())\n",
    "tree_regressor = DecisionTreeRegressor(criterion = 'squared_error', random_state=42)\n",
    "tree_regressor.fit(X, y)\n",
    "\n",
    "# prediciamo sul test set:\n",
    "test_set_scaled = scaler.transform(test_set.drop(\"quality\", axis=1))\n",
    "test_set_scaled = pd.DataFrame(test_set_scaled, columns=test_set.columns[:-1])\n",
    "test_set_scaled[\"quality\"] = test_set[\"quality\"].reset_index(drop=True)\n",
    "X_test = test_set_scaled.drop(\"quality\", axis=1)\n",
    "y_test = test_set_scaled[\"quality\"]\n",
    "\n",
    "y_pred = tree_regressor.predict(X_test)\n",
    "\n",
    "# valutiamo le prestazioni del modello:\n",
    "print(\"Pred: \", y_pred[0], \"True: \", y_test.iloc[0])\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error on the test set:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfe6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizziamo un grafico delle importanze delle feature:\n",
    "import matplotlib.pyplot as plt\n",
    "importances = tree_regressor.feature_importances_\n",
    "feature_names = X.columns\n",
    "plt.barh(feature_names, importances)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importances in the Decision Tree Regressor\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
